Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	analyze
	1	calc_vals
	1	get_data
	1	plot
	1	run_sims
	1	summary
	6

[Tue Nov 10 13:26:41 2020]
rule get_data:
    input: simulation.slim
    output: 10000_5_test.txt
    jobid: 5

[Tue Nov 10 13:32:46 2020]
Finished job 5.
1 of 6 steps (17%) done

[Tue Nov 10 13:32:46 2020]
rule calc_vals:
    input: 10000_5_test.txt
    output: 10000_5_data.txt
    jobid: 4

[Tue Nov 10 13:32:49 2020]
Finished job 4.
2 of 6 steps (33%) done

[Tue Nov 10 13:32:49 2020]
rule run_sims:
    input: 10000_5_data.txt
    output: 10000_5.txt
    jobid: 3

[Tue Nov 10 13:39:31 2020]
Finished job 3.
3 of 6 steps (50%) done

[Tue Nov 10 13:39:31 2020]
rule analyze:
    input: 10000_5.txt
    output: 10000_5_analysis.txt
    jobid: 2

[Tue Nov 10 13:39:33 2020]
Finished job 2.
4 of 6 steps (67%) done

[Tue Nov 10 13:39:33 2020]
rule summary:
    input: 10000_5_analysis.txt
    output: summary.csv
    jobid: 1

[Tue Nov 10 13:39:34 2020]
Finished job 1.
5 of 6 steps (83%) done

[Tue Nov 10 13:39:34 2020]
rule plot:
    input: summary.csv
    output: plot.png
    jobid: 0

[Tue Nov 10 13:39:35 2020]
Finished job 0.
6 of 6 steps (100%) done
Complete log: /Users/ecevarol/Desktop/Research/lower_threshold_project/pop_5000/.snakemake/log/2020-11-10T132639.786401.snakemake.log
