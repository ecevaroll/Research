Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	get_data
	1

[Thu Oct  1 20:37:43 2020]
rule get_data:
    input: simulation.slim
    output: 10000_1_test.txt
    jobid: 0
    wildcards: L=10000, T=1

RuleException in line 4 of /Users/ecevarol/Desktop/Research/lower_threshold_project/Snakefile:
NameError: The name 'L' is unknown in this context. Please make sure that you defined that variable. Also note that braces not used for variable access have to be escaped by repeating them, i.e. {{print $1}}
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 111, in run_jobs
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 402, in run
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 203, in _run
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 131, in _run
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 137, in printjob
