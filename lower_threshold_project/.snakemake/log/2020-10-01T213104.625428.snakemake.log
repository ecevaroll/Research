Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	get_data
	1

[Thu Oct  1 21:31:05 2020]
rule get_data:
    input: simulation.slim
    output: 10000_1_test.txt, 10000_5_test.txt, 1000_1_test.txt, 1000_5_test.txt
    jobid: 0

RuleException in line 6 of /Users/ecevarol/Desktop/Research/lower_threshold_project/Snakefile:
'InputFiles' object has no attribute 'L'
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 111, in run_jobs
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 402, in run
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 203, in _run
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 131, in _run
  File "/Users/ecevarol/opt/miniconda3/envs/snakemake/lib/python3.8/site-packages/snakemake/executors/__init__.py", line 137, in printjob
