Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	analyze
	1	calc_vals
	1	get_data
	1	run_sims
	4

[Wed Oct  7 22:15:20 2020]
rule get_data:
    input: simulation.slim
    output: 10000_1_test.txt, 10000_100_test.txt, 10000_5_test.txt, 10000_10_test.txt, 10000_30_test.txt
    jobid: 3

[Wed Oct  7 22:29:57 2020]
Finished job 3.
1 of 4 steps (25%) done

[Wed Oct  7 22:29:57 2020]
rule calc_vals:
    input: 10000_1_test.txt, 10000_100_test.txt, 10000_5_test.txt, 10000_10_test.txt, 10000_30_test.txt
    output: 10000_1_data.txt, 10000_100_data.txt, 10000_5_data.txt, 10000_10_data.txt, 10000_30_data.txt
    jobid: 2

[Wed Oct  7 22:29:58 2020]
Finished job 2.
2 of 4 steps (50%) done

[Wed Oct  7 22:29:58 2020]
rule run_sims:
    input: 10000_1_data.txt, 10000_100_data.txt, 10000_5_data.txt, 10000_10_data.txt, 10000_30_data.txt
    output: 10000_1.csv, 10000_100.csv, 10000_5.csv, 10000_10.csv, 10000_30.csv
    jobid: 1

[Wed Oct  7 22:45:05 2020]
Finished job 1.
3 of 4 steps (75%) done

[Wed Oct  7 22:45:05 2020]
rule analyze:
    input: 10000_1.csv, 10000_100.csv, 10000_5.csv, 10000_10.csv, 10000_30.csv
    output: summary.csv
    jobid: 0

[Wed Oct  7 22:45:07 2020]
Finished job 0.
4 of 4 steps (100%) done
Complete log: /Users/ecevarol/Desktop/Research/lower_threshold_project/.snakemake/log/2020-10-07T221519.066368.snakemake.log
