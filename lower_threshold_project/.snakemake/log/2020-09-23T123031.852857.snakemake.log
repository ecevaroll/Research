Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	calc_vals
	1	get_data
	1	run_sims
	3

[Wed Sep 23 12:30:32 2020]
rule get_data:
    input: simulation.slim
    output: 10000_1_test.txt
    jobid: 2

[Wed Sep 23 12:35:17 2020]
Finished job 2.
1 of 3 steps (33%) done

[Wed Sep 23 12:35:17 2020]
rule calc_vals:
    input: 10000_1_test.txt
    output: data.txt
    jobid: 1

[Wed Sep 23 12:35:19 2020]
Finished job 1.
2 of 3 steps (67%) done

[Wed Sep 23 12:35:19 2020]
rule run_sims:
    input: data.txt, simulation.slim
    output: 10000_1.txt
    jobid: 0

[Wed Sep 23 12:35:19 2020]
Error in rule run_sims:
    jobid: 0
    output: 10000_1.txt
    shell:
        slim -d envVar=headdata.txt -d adjustment=taildata.txt -d L=1e4 -d thres=1 simulation.slim
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/ecevarol/Desktop/Research/lower_threshold_project/.snakemake/log/2020-09-23T123031.852857.snakemake.log
