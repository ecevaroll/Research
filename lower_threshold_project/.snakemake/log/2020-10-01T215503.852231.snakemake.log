Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	get_data
	1

[Thu Oct  1 21:55:04 2020]
rule get_data:
    input: simulation.slim
    output: 10000_1_test.txt, 10000_5_test.txt, 1000_1_test.txt, 1000_5_test.txt
    jobid: 0

[Thu Oct  1 21:55:05 2020]
Error in rule get_data:
    jobid: 0
    output: 10000_1_test.txt, 10000_5_test.txt, 1000_1_test.txt, 1000_5_test.txt
    shell:
        for i in 10000 1000 do slim -d envVar=0.05 -d adjustment=0 -d L=i -d thres=1 simulation.slim done
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/ecevarol/Desktop/Research/lower_threshold_project/.snakemake/log/2020-10-01T215503.852231.snakemake.log
